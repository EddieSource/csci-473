{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning (CSCI-UA.473)\n",
    "\n",
    "## Lab 4: Logistic Regression Recap, Metrics for Classification and Support Vector Machines\n",
    "### Date: March 3rd, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "# Install autograd:\n",
    "#!conda install -c conda-forge autograd\n",
    "\n",
    "import autograd.numpy as numpy\n",
    "import autograd.numpy.random as npr\n",
    "\n",
    "from autograd import grad,elementwise_grad\n",
    "\n",
    "import scipy.optimize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "\n",
    "# For the plots in this notebook we will use a widget to get interactive and better looking plots! \n",
    "# follow these instructions to set up matplotlib widget for Jupyter Lab\n",
    "# https://github.com/matplotlib/jupyter-matplotlib#installation\n",
    "# Specifically you will need to install the widget using : conda install -c conda-forge ipympl\n",
    "# To enable the widget run the following two commands :\n",
    "# jupyter nbextension install --py --symlink --sys-prefix --overwrite ipympl\n",
    "#jupyter nbextension enable --py --sys-prefix ipympl\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Logistic Regression using Synthetic Data and Autograd\n",
    "\n",
    "We will play around with the logistic regression model implemented from scratch and trained using autograd on synthetic data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_seed = numpy.random.randint(0,100)\n",
    "random_seed = 65\n",
    "\n",
    "x, y = datasets.make_blobs(n_samples=2000, centers=2, n_features=2, random_state=random_seed)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(x[:,0], x[:,1], c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a set of data points $\\{(x_{1}, y_{1}), (x_{2}, y_{2}), ... , (x_{n}, y_{n})\\}$, where $x_{i} \\in R^{d}$ are the feature vectors and $y_{i} \\in \\{0, 1\\}$ are the class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training set and validation set\n",
    "We consider the first 1500 points as our training set and the remaining 500 as our validation set. \n",
    "<b>Is this correct?</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = x[:1500], y[:1500]\n",
    "x_val, y_val = x[1500:], y[1500:]\n",
    "\n",
    "# sanity check\n",
    "assert len(x_train) == len(y_train) == 1500\n",
    "assert len(x_val) == len(y_val) == 500\n",
    "\n",
    "# should we check anything else? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model\n",
    "Logistic regression model outputs the posterior probability of the class label to be equal to 1. \n",
    "$$p_{+} = p(y = 1|x) = \\frac{1}{1 + e^{-w \\cdot x + b}},$$ \n",
    "where $w \\in R^{d}$ and $b \\in R$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid function is used to convert the output of the linear operation into probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(a):\n",
    "    return 1. / (1. + numpy.exp(-a))\n",
    "\n",
    "def plot_function(f):\n",
    "    x = numpy.linspace(-10,10,100)\n",
    "    y = f(x)\n",
    "    \n",
    "    return plt.plot(x,y)\n",
    "\n",
    "plt.figure()\n",
    "plot_function(sigmoid)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_unit(x, w, b):\n",
    "    \"\"\"This function computes logistic unit as defined $p_{+}$ above\n",
    "    :param x: input x with n_dim features\n",
    "    :param w: weght vector\n",
    "    :param b: bias vector\n",
    "    \"\"\"\n",
    "    \n",
    "    # operator @ means matrix multiplication in python <3.5\n",
    "    # https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.matmul.html#numpy.matmul\n",
    "    \n",
    "    pre_sigmoid = x @ w + b\n",
    "    logit = sigmoid(pre_sigmoid)\n",
    "    \n",
    "    return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "The loss function of the logistic regression is given by: \n",
    "\n",
    "$$\\mathcal{L}(x,y) = - ( y \\cdot \\log(p_{+}) + (1 - y) \\cdot \\log(1 - p_{+}) )$$\n",
    "\n",
    "Note that $p_{+}$ depends on $x$ and $w$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEAR_ZERO = 1e-12\n",
    "\n",
    "def loss_function(x, y, w, b):\n",
    "    \"\"\"This function computes the loss (distance)\n",
    "    :param logits: output from logistic unit\n",
    "    :param labels: target label\n",
    "    \"\"\"\n",
    "    logits = logistic_unit(x,w,b)\n",
    "    labels = y\n",
    "    \n",
    "    loss = -(labels * numpy.log(logits + NEAR_ZERO) + (1 - labels) * numpy.log(1 - logits + NEAR_ZERO))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets do a sanity check and compute the loss between the target and prediction given a randomly initialized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "n_dim=2\n",
    "w0 = 0.1 * numpy.random.randn(n_dim)\n",
    "b0 = 0.0\n",
    "\n",
    "inp = x_train[0]\n",
    "label = y_train[0]\n",
    "\n",
    "out = logistic_unit(inp, w0, b0)\n",
    "assert (out < 1) and (out > 0)  # why?\n",
    "\n",
    "loss = loss_function(inp, label, w0, b0)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Autograd for computing the derivatives and train the model\n",
    "As discussed in the previous lab, with Autograd we do not need to compute the gradients by hand and code it. This is very handy when we have huge DAG (Directed Acyclic Graph) computations.\n",
    "There is an active line of research in automatic differentiation, curious students are adviced to read this:\n",
    "http://jmlr.org/papers/volume18/17-468/17-468.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_grad_w = elementwise_grad(loss_function, 2) # partial derivative wrt the weights w (3rd input)\n",
    "loss_grad_b = elementwise_grad(loss_function, 3) # partial derivative wrt the bias b (4th input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 10000\n",
    "eta = .0001   # Learning rate\n",
    "w = numpy.copy(w0)\n",
    "b = numpy.copy(b0)\n",
    "\n",
    "loss_log = []\n",
    "\n",
    "for ni in tqdm(range(n_iter)):\n",
    "    dw = loss_grad_w(x_train, y_train, w, b)\n",
    "    db = loss_grad_b(x_train, y_train, w, b)\n",
    "    w -= eta * dw\n",
    "    b -= eta * db\n",
    "    \n",
    "    loss = numpy.mean(loss_function(x_train, y_train, w, b))\n",
    "    loss_log.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot the running element-wise loss value\n",
    "plt.figure()\n",
    "plt.plot(loss_log)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the data: the actual data and the model (hyperplane)\n",
    "We start with first defining some visualization routines and then we do the actual plotting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Justsome visualization routines. As always, don't focus on the details of these routines too much!\n",
    "# visualize data \n",
    "def vis_data(x, y = None):\n",
    "    if y is None: \n",
    "        y = [None] * len(x)\n",
    "    for x_, y_ in zip(x, y):\n",
    "        if y_ is None:\n",
    "            plt.plot(x_[0], x_[1], 'o', markerfacecolor='none', markeredgecolor=c)\n",
    "        else:\n",
    "            plt.plot(x_[0], x_[1], 'b'+'o' if y_ == 0 else 'y'+'+')\n",
    "    plt.grid('on')\n",
    "    \n",
    "def vis_hyperplane(w, b, typ='k--'):\n",
    "\n",
    "    lim0 = plt.gca().get_xlim()\n",
    "    lim1 = plt.gca().get_ylim()\n",
    "    m0, m1 = lim0[0], lim0[1]\n",
    "\n",
    "    intercept0 = -(w[0] * m0 + b)/w[1]\n",
    "    intercept1 = -(w[0] * m1 + b)/w[1]\n",
    "    \n",
    "    plt1, = plt.plot([m0, m1], [intercept0, intercept1], typ)\n",
    "\n",
    "    plt.gca().set_xlim(lim0)\n",
    "    plt.gca().set_ylim(lim1)\n",
    "        \n",
    "    return plt1\n",
    "\n",
    "def vis_decision_boundary_contour(w, b, typ='k--'):\n",
    "    \n",
    "    lim0 = plt.gca().get_xlim()\n",
    "    lim1 = plt.gca().get_ylim()\n",
    "    \n",
    "    x_ = numpy.linspace(lim0[0], lim0[1], 100)\n",
    "    y_ = numpy.linspace(lim1[0], lim1[1], 100)\n",
    "    xx, yy = numpy.meshgrid(x_, y_)\n",
    "    \n",
    "    x_tra_ = numpy.concatenate([xx.ravel()[:,None], yy.ravel()[:,None]], axis=1)\n",
    "    \n",
    "    pred = logistic_unit(x_tra_, w, b)\n",
    "    plt1 = plt.contourf(xx, yy, pred.reshape(xx.shape), cmap=plot.cm.coolwarm, alpha=0.4)\n",
    "    \n",
    "    plt.colorbar(plt1)\n",
    "    \n",
    "    plt.gca().set_xlim(lim0)\n",
    "    plt.gca().set_ylim(lim1)\n",
    "        \n",
    "    return plt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "vis_data(x, y)\n",
    "\n",
    "plt0 = vis_hyperplane(w0, b0, 'k--')\n",
    "plt1 = vis_hyperplane(w, b, 'k-')\n",
    "plt.legend([plt0, plt1], [\n",
    "        'Initial: ${:.2} x_1 + {:.2} x_2 + {:.2} = 0$'.format(*list(w0)+[b0]),\n",
    "        'Final: ${:.2} x_1 + {:.2} x_2 + {:.2} = 0$'.format(*list(w)+[b])],\n",
    "           loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Logistic Regression for Breast Cancer Classification using Sklearn\n",
    "\n",
    "We will now implement and train another logistic regression model using Sci-kit learn. The goal will be to implement the model, which given a new data point infers the probability of breast cancer. \n",
    "\n",
    "Helper method below copied from: [Helper Method](https://stackoverflow.com/questions/38105539/how-to-convert-a-scikit-learn-dataset-to-a-pandas-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General helper method to convert sci-kit datasets to Pandas DataFrame.\n",
    "def sklearn_to_df(sklearn_dataset):\n",
    "    df = pd.DataFrame(sklearn_dataset.data, columns=sklearn_dataset.feature_names)\n",
    "    df['target'] = pd.Series(sklearn_dataset.target)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's eyeball the data a little bit in a quick and hacky manner. Always a good practice to see what the data looks like. **The training data of course!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_dataset = datasets.load_breast_cancer() # Load the data and convert to a pandas dataframe\n",
    "df = sklearn_to_df(cancer_dataset)\n",
    "\n",
    "print(df.head()) # Print out the first five data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's gather a few summary statistics about our data. Again, always a good practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df) # The number of data points.\n",
    "print('N = {:d} data points'.format(N))\n",
    "\n",
    "# Give a barplot of each class.\n",
    "plt.figure()\n",
    "plt.bar([0,1], df['target'].value_counts(ascending = True), color = ['r', 'b'], tick_label = cancer_dataset.target_names)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Cancer Dataset: Class Counts');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is unbalanced because there are more examples of benign cancer than malignant.  This is typical of many real-life datasets where we are sometimes limited in how many training examples we have.  Let's split our data into a training and validation set.  We'll use a 80/20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data.  DO NOT TOUCH THE TEST DATA FROM HERE ON!!\n",
    "train_data, val_data = model_selection.train_test_split(df, test_size = 0.2) # 0.2 is 20% validation data.\n",
    "\n",
    "# Split the features from the class labels.\n",
    "X_train = train_data.drop('target', axis = 1) # We drop the target from the features.  \n",
    "X_val  = val_data.drop('target', axis = 1)  # Note that this does not operate inplace.\n",
    " \n",
    "y_train = train_data['target']\n",
    "y_val  = val_data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is loaded and split we can train a logistic regression model.  For the optimization we use the \"liblinear\" solver.  There are many other solvers that are also available, such as Newton CG for example.  For more information: [Solvers](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit a logistic regression model.\n",
    "model = LogisticRegression(solver = 'liblinear', class_weight = 'balanced')\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained so we can validate it on our validation set.  The Sci-kit metrics module contains many useful functions for this purpose.  We try out a few of them below. \n",
    "\n",
    "Let us first briefly explain some of these metrics we will use.  \n",
    "\n",
    "#### Accuracy \n",
    "Accuracy is obviously the percentage of all correctly classified examples in our test set.  \n",
    "\n",
    "#### Confusion Matrix\n",
    "The confusion matrix is the following matrix:\n",
    "$$\n",
    "C = \\begin{bmatrix}\n",
    "\\text{Predict 0, Actual 0} & \\text{Predict 0, Actual 1}\\\\\n",
    "\\text{Predict 1, Actual 0} & \\text{Predict 1, Actual 1}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Notice that the diagonal entries are the examples that are correctly classified.  \n",
    "\n",
    "#### Precision Score\n",
    "The precision score is the percentage \n",
    "$$\n",
    "\\text{Precision } = \\frac{C_{00}}{C_{00} + C_{01}}.\n",
    "$$\n",
    "So it is the percentage of predicted malignant tumors that we classify correctly.  \n",
    "\n",
    "#### Recall Score \n",
    "The recall score is the percentage\n",
    "$$\n",
    "\\text{Recall } = \\frac{C_{00}}{C_{00} + C_{10}}\n",
    "$$\n",
    "So it is the percentage of malignant tumors that we classify correctly. Note that Precision and Recall are two different quantities.\n",
    "\n",
    "**Using multiple evaluation metrics helps give a better picture of how well our classifier is doing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_val)\n",
    "\n",
    "# See the percentage of examples that are correctly classified.\n",
    "accuracy = metrics.accuracy_score(y_val, pred) \n",
    "print(\"Accuracy = {:0.1f}%\".format(accuracy * 100))\n",
    "\n",
    "# The matrix of predictions and true values for each class.\n",
    "conf_matrix = metrics.confusion_matrix(y_val, pred)\n",
    "print(\"Confusion matrix = \")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Precision score.\n",
    "precision = metrics.precision_score(y_val, pred)\n",
    "print(\"Precision = {:0.1f}%\".format(100 * precision))\n",
    "\n",
    "# Recall score.\n",
    "recall = metrics.recall_score(y_val, pred)\n",
    "print(\"Recall    = {:0.1f}%\".format(100 * recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines\n",
    "We will now play around with the support vector machine. We will first compare them to a standard logistic regression model. Then we will see how they work on datasets which are not linearly separable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import some necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing the packages we'll need.\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Linear SVMs\n",
    "We will implement a linear SVM for the task of breast cancer classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load the dataset and split it into training and validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll set a random seed first.\n",
    "np.random.seed(19)\n",
    "\n",
    "# First load the data.\n",
    "data = datasets.load_breast_cancer()\n",
    "X = data.data   # The features.\n",
    "y = data.target # The targets.\n",
    "\n",
    "# Print the dataset sizes.\n",
    "print('Shape of X = ', X.shape)\n",
    "print('Shape of y = ', y.shape)\n",
    "\n",
    "# Split the data into a training and test set.\n",
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X, y, test_size = 0.33, random_state = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train a linear SVM using scikit-learn. In addition also train a logistic regression model also using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the linear SVM.\n",
    "\n",
    "svm = LinearSVC(dual = False) # Uses the squared-hinge loss function when fitting the model.\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Now evaluate it on the test points.\n",
    "y_pred = svm.predict(X_val)\n",
    "\n",
    "acc = metrics.accuracy_score(y_val, y_pred)\n",
    "print('Linear SVM validation accuracy = {:0.1f}%'.format(100*acc))\n",
    "\n",
    "# Compare to a simple logistic regression model.\n",
    "\n",
    "lr = LogisticRegression(solver = 'liblinear')\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "acc = metrics.accuracy_score(y_val, y_pred)\n",
    "print('Logistic Regression validation accuracy = {:0.1f}%'.format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, a basic linear SVM already does very well and is comparable to logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare logistic regression with SVM for binary classification.  Suppose that our data has $n$ features and we have trained a logistic regression model with weight vector $\\theta_{\\mathrm{LR}}\\in \\mathbb{R}^{n+1}$ as well as a linear SVM with parameters $w_{\\mathrm{SVM}}\\in \\mathbb{R}^n$, and $b_{\\mathrm{SVM}}\\in \\mathbb{R}$.  Assume that the optimal parameters have been found in both cases.  If the data is linearly separable then is it true that $\\theta_{\\mathrm{LR}} = (b_{\\mathrm{SVM}}, w_{\\mathrm{SVM}})$? \n",
    "\n",
    "If not then why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**They will not be the same in general.**\n",
    "\n",
    "Consider the dataset $X = (-5, -1, 1, 2)^T$ and $y = (-1, -1, 1, 1)^T$ (equivalently $y = (0,0,1,1)^T$ for logistic regression).  The SVM parameters will just be $(b_{\\mathrm{SVM}}, w_{\\mathrm{SVM}}) = (0,1)$.  However, the logistic regression parameters will be slightly different.  Recall the gradient of the loss function for logistic regression is\n",
    "$$\n",
    "\\nabla_{\\theta}J(\\theta) = -\\sum_{i=1}^4 (y_i - h(X_i;\\theta))X_i\n",
    "$$\n",
    "where\n",
    "$$\n",
    "h(x;\\theta) = \\frac{1}{1 + \\exp(-\\theta^Tx)}\n",
    "$$\n",
    "However, if we plug all of the values into the gradient we get\n",
    "$$\n",
    "\\nabla_{\\theta}J((b_{\\mathrm{SVM}}, w_{\\mathrm{SVM}})) = -\\left( \\frac{5}{1+e^{5}} + \\frac{1}{1+e^{1}} + \\frac{e^{-1}}{1+e^{-1}} +  \\frac{2e^{-2}}{1 + e^{-2}} \\right) \\neq 0\n",
    "$$\n",
    "Since the gradient is non-zero we know that $(b_{\\mathrm{SVM}}, w_{\\mathrm{SVM}})$ is not the optimal value for the logistic regression loss function and hence cannot be $\\theta_{\\mathrm{LR}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case of non-linearly separable dataset\n",
    "\n",
    "If the data is linear separable, then a linear SVM should be able to achieve 100% accuracy.  However, this is rarely the case since even the breast cancer dataset was not exactly linear separable.  We'll use a synthetic dataset to illustrate this.  This data is drawn from a bi-modal Gaussian mixture model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:\n",
    "    N : the number of data points\n",
    "\n",
    "Output:\n",
    "    X, y : the features and targets of shapes (N,2) and (N, )\n",
    "\"\"\"\n",
    "def sample_bimodal_data(N):\n",
    "    \n",
    "    # The two modes and covariances.\n",
    "    mu1 = np.asarray([-1, 0])\n",
    "    mu2 = np.asarray([1, 0])\n",
    "    \n",
    "    cov1 = 2 * np.identity(2)\n",
    "    cov2 = 2 * np.identity(2)\n",
    "    \n",
    "    N1 = N//2   # Number of points in first class.\n",
    "    N2 = N - N1 # Number of points in second class.\n",
    "    \n",
    "    # Sample the random points.\n",
    "    X1 = np.random.multivariate_normal(mu1, cov1, N1)\n",
    "    X2 = np.random.multivariate_normal(mu2, cov2, N2)\n",
    "    Y1 = np.zeros(N1)\n",
    "    Y2 = np.ones(N2)\n",
    "    \n",
    "    # Combine the data.\n",
    "    X = np.vstack((X1, X2))\n",
    "    Y = np.concatenate((Y1, Y2), axis = None)\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the sample data.\n",
    "N = 100\n",
    "X,Y = sample_bimodal_data(N)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.scatter(X[:N//2, 0], X[:N//2, 1], label = 'Class 0')\n",
    "plt.scatter(X[N - N//2:, 0], X[N - N//2:, 1], label = 'Class 1')\n",
    "plt.legend()\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.title('Sample Data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the factor in front of the covariances or shifting the centers of the two distributions to be closer to each other will cause the data to overlap more, making it harder to classify. Lets try that! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a slack variable C\n",
    "\n",
    "Since the data is not perfectly linearly separable you'll want to use a slack variable which allows SVM to handle this dataset.  Let's train some models with different values of $C$ and compare them using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get the data and split it into training and testing.\n",
    "\n",
    "N = 100\n",
    "X, Y = sample_bimodal_data(N)\n",
    "\n",
    "# Use a 70/30 split\n",
    "X_train, X_val, Y_train, Y_val = model_selection.train_test_split(X, Y, test_size = 0.30, random_state = 981)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SVM model to use with a slack variable\n",
    "svm = LinearSVC(C = 1e-10, dual = False)\n",
    "svm.fit(X_train, Y_train)\n",
    "svmpred = svm.predict(X_val)\n",
    "acc = metrics.accuracy_score(Y_val, svmpred)\n",
    "print('SVM accuracy = {:0.1f}%'.format(100*acc))\n",
    "\n",
    "plt.figure(2)\n",
    "I = svmpred == 0\n",
    "plt.scatter(X_val[I, 0], X_val[I, 1], label = 'Predicted class 0')\n",
    "I = svmpred == 1\n",
    "plt.scatter(X_val[I, 0], X_val[I, 1], label = 'Predicted class 1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment with various different mu1 values and demonstrate SVM accuracy gets worse as mu1 and mu2 get closer**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train some models with different $C$ and compare them use cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the different SVM models to use\n",
    "svm_1 = LinearSVC(C = 10, dual = False)\n",
    "svm_2 = LinearSVC(C = 1, dual = False)\n",
    "svm_3 = LinearSVC(C = 1e-3, dual = False)\n",
    "svm_4 = LinearSVC(C = 1e-7, dual = False)\n",
    "\n",
    "split = model_selection.KFold(5)\n",
    "# Get the CV scores.\n",
    "cv_1 = model_selection.cross_val_score(svm_1, X_train, Y_train, cv = split)\n",
    "cv_2 = model_selection.cross_val_score(svm_2, X_train, Y_train, cv = split)\n",
    "cv_3 = model_selection.cross_val_score(svm_3, X_train, Y_train, cv = split)\n",
    "cv_4 = model_selection.cross_val_score(svm_4, X_train, Y_train, cv = split)\n",
    "\n",
    "# Print the average scores.\n",
    "print('C = 10    CV average score = {:0.1f}%'.format(np.mean(cv_1) * 100))\n",
    "print('C = 1     CV average score = {:0.1f}%'.format(np.mean(cv_2) * 100))\n",
    "print('C = 1e-3  CV average score = {:0.1f}%'.format(np.mean(cv_3) * 100))\n",
    "print('C = 1e-7  CV average score = {:0.1f}%'.format(np.mean(cv_4) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the model performs slightly differently for different values of the slack variable $C$.  \n",
    "\n",
    "$$\n",
    "\\min_{w,b,\\zeta} \\frac{1}{2}w^Tw + C\\sum_{i=1}^n \\zeta_i,\\quad \\text{ such that }\\quad y_i(w^Tx_i + b) \\ge 1 - \\zeta_i,\\quad \\zeta_i \\ge 0\n",
    "$$\n",
    "\n",
    "See the sci-kit [documentation](https://scikit-learn.org/stable/modules/svm.html) for more details.  We can also plot a curve of the validation score for many different $C$ values which can be helpful for determining the optimal hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the C values we want to look at.\n",
    "C = 1/(2**np.arange(0, 20)) # 1,...,1e-6\n",
    "\n",
    "k = 10 # Kfold CV.\n",
    "cv_scores = np.zeros(len(C))\n",
    "split = model_selection.KFold(k)\n",
    "for i in range(len(C)):\n",
    "    svm = LinearSVC(C = C[i], dual = False)\n",
    "    cv_scores[i] = np.mean(model_selection.cross_val_score(svm, X_train, Y_train, cv = split))\n",
    "\n",
    "plt.figure(2)\n",
    "plt.semilogx(C, cv_scores, 'b-x')\n",
    "plt.xlabel(r'$C$')\n",
    "plt.ylabel(r'Score')\n",
    "plt.title(r'{:d}-Fold CV Score for Linear SVM'.format(k))\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this plot to find the optimal value of the slack variables based on the cross validation score. Now let's see how our 4 models from earlier actually do on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the different SVM models to use\n",
    "svm_1 = LinearSVC(C = 10, dual = False)\n",
    "svm_2 = LinearSVC(C = 1, dual = False)\n",
    "svm_3 = LinearSVC(C = 1e-3, dual = False)\n",
    "svm_4 = LinearSVC(C = 1e-7, dual = False)\n",
    "\n",
    "# Fit the models.\n",
    "svm_1.fit(X_train, Y_train)\n",
    "svm_2.fit(X_train, Y_train)\n",
    "svm_3.fit(X_train, Y_train)\n",
    "svm_4.fit(X_train, Y_train)\n",
    "\n",
    "# Make the predictions.\n",
    "pred1 = svm_1.predict(X_val)\n",
    "pred2 = svm_2.predict(X_val)\n",
    "pred3 = svm_3.predict(X_val)\n",
    "pred4 = svm_4.predict(X_val)\n",
    "\n",
    "# Evaluate the models.\n",
    "acc1 = metrics.accuracy_score(Y_val, pred1)\n",
    "acc2 = metrics.accuracy_score(Y_val, pred2)\n",
    "acc3 = metrics.accuracy_score(Y_val, pred3)\n",
    "acc4 = metrics.accuracy_score(Y_val, pred4)\n",
    "\n",
    "print('Linear SVM (C = 10)   accuracy = {:0.1f}%'.format(100*acc1))\n",
    "print('Linear SVM (C = 1)    accuracy = {:0.1f}%'.format(100*acc2))\n",
    "print('Linear SVM (C = 1e-3) accuracy = {:0.1f}%'.format(100*acc3))\n",
    "print('Linear SVM (C = 1e-7) accuracy = {:0.1f}%'.format(100*acc4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another non-linearly separable dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:\n",
    "    N : the number of data points\n",
    "\n",
    "Output:\n",
    "    X, y : the features and targets of shapes (N,2) and (N, )\n",
    "\"\"\"\n",
    "def gen_data1(N):\n",
    "    N1 = N//2\n",
    "    N2 = N - N1\n",
    "    t = np.linspace(0, 2*np.pi, N1)\n",
    "    \n",
    "    X1 = np.zeros((N1, 2))\n",
    "    X1[:,0] = 4*np.cos(t) + 0.1*np.random.randn(N1)\n",
    "    X1[:,1] = 4*np.sin(t) + 0.1*np.random.randn(N1)\n",
    "    y1 = np.zeros(N1)\n",
    "    \n",
    "    X2 = np.random.randn(2*N2)\n",
    "    X2 = X2.reshape((N2, 2))\n",
    "    y2 = np.ones(N2)\n",
    "\n",
    "    # Combine the data.\n",
    "    X = np.vstack((X1, X2))\n",
    "    y = np.concatenate((y1, y2), axis = None) # axis = None means that arrays flattened before use\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data.\n",
    "N = 1000\n",
    "X, Y = gen_data1(N)\n",
    "\n",
    "plt.figure(3)\n",
    "plt.scatter(X[:N//2, 0], X[:N//2, 1], label = 'Class 0')\n",
    "plt.scatter(X[N - N//2:, 0], X[N - N//2:, 1], label = 'Class 1')\n",
    "plt.legend()\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.title('Sample Data');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the different SVM models to use\n",
    "# Use a 70/30 split\n",
    "X_train, X_val, Y_train, Y_val = model_selection.train_test_split(X, Y, test_size = 0.3, random_state = 981)\n",
    "svm = LinearSVC(C = 1e+10, dual = False)\n",
    "svm.fit(X_train, Y_train)\n",
    "svmpred = svm.predict(X_val)\n",
    "acc = metrics.accuracy_score(Y_val, svmpred)\n",
    "print('SVM accuracy = {:0.1f}%'.format(100*acc))\n",
    "\n",
    "plt.figure(2)\n",
    "I = svmpred == 0\n",
    "plt.scatter(X_val[I, 0], X_val[I, 1], label = 'predicted class 0')\n",
    "I = svmpred == 1\n",
    "plt.scatter(X_val[I, 0], X_val[I, 1], label = 'prediced class 1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the data is not linearly separable although we can very clearly see some separation. If we transform the data by only looking at the radius, then we would be able to linearly separate the data. We will visit this in the next lecture when we talk about kernel SVM's which are much more flexible models and can handle a wider array of datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart2pol(x, y):\n",
    "    rho = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    return (rho, phi)\n",
    "\n",
    "pX = np.vstack(cart2pol(X[:, 0], X[:, 1])).T\n",
    "print(pX.shape)\n",
    "plt.figure(4)\n",
    "plt.scatter(pX[:N//2, 0], pX[:N//2, 1], label = 'Class 0')\n",
    "plt.scatter(pX[N - N//2:, 0], pX[N - N//2:, 1], label = 'Class 1')\n",
    "plt.legend()\n",
    "plt.xlabel(r'$p_1$ (radius)')\n",
    "plt.ylabel(r'$p_2$ (angle)')\n",
    "plt.title('Sample Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the different SVM models to use\n",
    "# Use a 70/30 split\n",
    "X_train, X_val, Y_train, Y_val = model_selection.train_test_split(pX, Y, test_size = 0.3, random_state = 981)\n",
    "svm = LinearSVC(C = 1e+10, dual = False)\n",
    "svm.fit(X_train, Y_train)\n",
    "svmpred = svm.predict(X_val)\n",
    "acc = metrics.accuracy_score(Y_val, svmpred)\n",
    "print('SVM accuracy = {:0.1f}%'.format(100*acc))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
